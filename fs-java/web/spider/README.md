# 数据采集

## 架构设计

### 角色

- 服务端（Spider）：用于配置和分发作业，负责任务调度、状态存储、采集结果数据存储。
- 采集端（Crawler）：从服务端获取任务，执行完成后将结果提交回服务端，若响应类型为文件，则转存到文件存储。
- 清洗端（ETL）：将采集的原始数据，按照一定的规则处理为高质量的业务数据，同时将正文中的图片转存到图床。
> 清洗算法：页面类型判定（首页、列表页、详情页等）、新渠道发现、列表首页标记、详情提取。

### 原则

- 全量采集：只要在白名单中的站点，尽可能高效全面的采集下来。
- 增量采集：根据清洗端标记的列表首页，定期进行回溯，根据列表项重复率确定是否进行翻页。
- 存储方式：服务端负责将采集结果存储到Mongo集合，采集端在请求链接时负责将文件转存到MinIO桶，清洗端负责将正文中的图片写入到图床。

### 实体

- 作业：为避免资源浪费，每个模板仅保留一个调度作业。通过发布操作将模板配置同步到作业，通过运行操作执行作业调度，多次执行操作共享同一个调度队列。
- 请求频率：全局共享，防止多个作业请求同一域名，导致请求数过多。可以通过设置每作业、每域名、每节点、每代理，控制请求数的共享范围。

### 配置

- 作业最大线程数：限制作业可申请的最大资源数量。
- 请求频率并行度：按共享范围，限制同时在执行的请求数量。
- 请求频率并发数：按共享范围，限制特定间隔内已发出请求的数量。
